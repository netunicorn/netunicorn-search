{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ebbad-088c-4284-b641-a8cae527bc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from trustee import ClassificationTrustee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725d89f-bc44-4d81-9f70-832f6722bea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool_1_ips = {\n",
    "    '169.231.210.93',\n",
    "    '169.231.28.232',\n",
    "    '169.231.123.195',\n",
    "    '169.231.172.165',\n",
    "    '169.231.11.193',\n",
    "    '169.231.8.190',\n",
    "    '169.231.10.199'\n",
    "}\n",
    "\n",
    "pool_2_ips = {\"128.111.52.37\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86c0b9-2daa-4f17-a15c-ca8443d41135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset(prefix: str):\n",
    "    dataset_1 = pd.read_csv(f'{prefix}_cicfeatures_1.csv')\n",
    "    dataset_1['Class'] = 0\n",
    "    dataset_1.loc[dataset_1['Src IP'].isin(pool_1_ips), 'Class'] = 1\n",
    "    ttl_data_1 = pd.read_csv(f'{prefix}_ttl_1.csv')\n",
    "    dataset_1 = dataset_1.merge(ttl_data_1, on=\"Flow ID\", how='left')\n",
    "    \n",
    "    dataset_2 = pd.read_csv(f'{prefix}_cicfeatures_2.csv')\n",
    "    dataset_2['Class'] = 0\n",
    "    dataset_2.loc[dataset_2['Src IP'].isin(pool_2_ips), 'Class'] = 1\n",
    "    ttl_data_2 = pd.read_csv(f'{prefix}_ttl_2.csv')\n",
    "    dataset_2 = dataset_2.merge(ttl_data_2, on=\"Flow ID\", how='left')\n",
    "    \n",
    "    dataset = pd.concat([dataset_1, dataset_2])\n",
    "    dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "    dataset = dataset.dropna(axis=0)\n",
    "    dataset = dataset.drop([\n",
    "        'Flow ID',\n",
    "        'Src IP',\n",
    "        'Dst IP',\n",
    "        'Timestamp', \n",
    "        'Protocol',    # always tcp\n",
    "        'Label',       # empty\n",
    "    ], axis=1)\n",
    "    dataset.to_csv(f'{prefix}_dataset.csv')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d902c4b-c436-4d58-a9b4-48548a4a4f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6c9a5-ada4-4abb-9623-422679145b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_visualize(dataset, clf, visualize_tree = False):\n",
    "    target_variable = 'Class'\n",
    "    features = list(sorted(set(dataset.columns) - {target_variable}))\n",
    "    x_data = dataset[features]\n",
    "    y_data = dataset[target_variable]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25)\n",
    "    \n",
    "    x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "    x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "    \n",
    "    trained_clf = clf.fit(x_train, y_train)\n",
    "    prediction = trained_clf.predict(x_test)\n",
    "    print(metrics.classification_report(y_test, prediction))\n",
    "    \n",
    "    trustee = ClassificationTrustee(expert=trained_clf)\n",
    "    trustee.fit(x_train, y_train, num_iter=10, num_stability_iter=3, samples_size=0.8)\n",
    "    \n",
    "    _, dt, _, score = trustee.explain()\n",
    "    print(f\"Training score of pruned DT: {score}\")\n",
    "    dt_y_pred = dt.predict(x_test)\n",
    "    \n",
    "    print(\"Model explanation global fidelity report:\")\n",
    "    print(metrics.classification_report(prediction, dt_y_pred))\n",
    "    print(\"Model explanation score report:\")\n",
    "    print(metrics.classification_report(y_test, dt_y_pred))\n",
    "    \n",
    "    fig = plt.figure(figsize=(25,20))\n",
    "    plot_tree(dt, feature_names=x_train.columns, class_names=['benign', 'attack'], filled=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841391d7-e44a-4df3-9ec8-b246d7f156af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "campus_dataset = read_dataset('campus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd537d-e81f-40c4-92f4-5ae572ec2364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "train_and_visualize(campus_dataset, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9ba9d-c8ab-44bf-ad9e-f131cd5825ae",
   "metadata": {},
   "source": [
    "Let's train whitebox model to double-check Trustee output due to high imbalance of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d755f5-7c0c-4f5f-b4ff-2e86d9df4bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "target_variable = 'Class'\n",
    "features = list(sorted(set(campus_dataset.columns) - {target_variable}))\n",
    "x_data = campus_dataset[features]\n",
    "y_data = campus_dataset[target_variable]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25)\n",
    "x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "clf.fit(x_train, y_train)\n",
    "prediction = clf.predict(x_test)\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = plot_tree(clf, feature_names=x_train.columns, class_names=['benign', 'attack'], filled=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f584e4a-e94b-4fa3-ac04-466709e450ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "azure_dataset = read_dataset('azure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce30dd8-a48a-4d0d-8db9-e53080942344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool_1_ips = {\n",
    "    '157.245.108.149', # netunicorn-digitalocean-1\n",
    "    '34.214.149.122',  # netunicorn-aws-1\n",
    "}\n",
    "\n",
    "pool_2_ips = {\n",
    "    \"52.43.47.231\",   # netunicorn-aws-2\n",
    "    \"15.164.100.10\",  # netunicorn-aws-3\n",
    "    \"170.64.144.63\",  # netunicorn-digitalocean-2\n",
    "}\n",
    "multicloud_dataset = read_dataset('multicloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411c1c5-cc37-4bac-944f-bc5e76c8f338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352f7a7-406e-4caf-9a28-eb678afe8149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_variable = 'Class'\n",
    "features = list(set(campus_dataset.columns) - {target_variable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd62675-6364-4948-a9cc-3093ea1b50a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = campus_dataset[features]\n",
    "y_train = campus_dataset[target_variable]\n",
    "x_test = azure_dataset[features]\n",
    "y_test = azure_dataset[target_variable]\n",
    "x_test_2 = multicloud_dataset[features]\n",
    "y_test_2 = multicloud_dataset[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f82c1c-77e1-4e73-b6c9-a6ed2f21ab92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "x_test_2 = pd.DataFrame(StandardScaler().fit_transform(x_test_2), columns = x_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62541a24-83ea-487b-8ab6-ed5d1c372858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    MLPClassifier(alpha=1, max_iter=100),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    TabNetClassifier(verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713df12-5944-4722-802a-554cabd494c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(x_train.values, y_train.values)\n",
    "    y_pred = clf.predict(x_train.values)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "    print(\"Azure dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test.values)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2.values)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ff9fc-38db-4d7c-9b7a-ffa22b76fbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_variable = 'Class'\n",
    "features = list(set(campus_dataset.columns) - {target_variable})\n",
    "x_train = campus_dataset[features].copy()\n",
    "y_train = campus_dataset[target_variable]\n",
    "x_test = azure_dataset[features]\n",
    "y_test = azure_dataset[target_variable]\n",
    "x_test_2 = multicloud_dataset[features]\n",
    "y_test_2 = multicloud_dataset[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1e557-3068-4030-bd2f-f9ca51c3e9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train.loc[:, 'TTL'] += np.random.randint(-1, 1, [len(x_train)])\n",
    "x_train.loc[:, 'Bwd Init Win Bytes'] += np.random.randint(-5, 5, [len(x_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323013c2-e122-4e99-a110-d65c5a657cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "x_test_2 = pd.DataFrame(StandardScaler().fit_transform(x_test_2), columns = x_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02279856-73fe-4fe5-981b-f32ca4006811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    # MLPClassifier(),\n",
    "    # GradientBoostingClassifier(),\n",
    "    # RandomForestClassifier(),\n",
    "    TabNetClassifier(verbose=0),\n",
    "]\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(x_train.values, y_train.values)\n",
    "    y_pred = clf.predict(x_train.values)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "    # print(\"Azure dataset test accuracy: \")\n",
    "    # y_pred = clf.predict(x_test.values)\n",
    "    # print(metrics.classification_report(y_test, y_pred))\n",
    "    # print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2.values)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712a3bd-03e8-47b7-985d-fd54456d031d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['TTL', 'Bwd Init Win Bytes'], axis=1)\n",
    "x_test = x_test.drop(['TTL', 'Bwd Init Win Bytes'], axis=1)\n",
    "x_test_2 = x_test_2.drop(['TTL', 'Bwd Init Win Bytes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e66729-7b8d-4278-8eb9-2ec3970f174b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    MLPClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(max_depth=4),\n",
    "    TabNetClassifier(verbose=0),\n",
    "]\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(x_train.values, y_train.values)\n",
    "    y_pred = clf.predict(x_train.values)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "    print(\"Azure dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test.values)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2.values)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff4e94-65b8-4d65-8bde-aed06b651ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trustee = ClassificationTrustee(expert=classifiers[0])\n",
    "trustee.fit(x_train, y_train, num_iter=10, num_stability_iter=3, samples_size=0.8)\n",
    "\n",
    "_, dt, _, score = trustee.explain()\n",
    "print(f\"Training score of pruned DT: {score}\")\n",
    "dt_y_pred = dt.predict(x_test)\n",
    "\n",
    "print(\"Model explanation global fidelity report:\")\n",
    "print(metrics.classification_report(classifiers[0].predict(x_test), dt_y_pred))\n",
    "print(\"Model explanation score report:\")\n",
    "print(metrics.classification_report(y_test, dt_y_pred))\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "plot_tree(dt, feature_names=x_train.columns, class_names=['benign', 'attack'], filled=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ded470-1ce6-4329-aae6-9d428021a847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import smote_variants as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1997c38-f495-4f01-948c-ac975a0b3e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_variable = 'Class'\n",
    "features = list(set(campus_dataset.columns) - {target_variable})\n",
    "x_train = campus_dataset[features].copy()\n",
    "y_train = campus_dataset[target_variable]\n",
    "x_test = azure_dataset[features]\n",
    "y_test = azure_dataset[target_variable]\n",
    "x_test_2 = multicloud_dataset[features]\n",
    "y_test_2 = multicloud_dataset[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34859a52-03c3-429b-9391-49eae4180c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "x_test_2 = pd.DataFrame(StandardScaler().fit_transform(x_test_2), columns = x_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed40f9-0fa2-4114-813a-ad04f537fb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oversampler = sv.SMOTE()\n",
    "X_samp, y_samp = oversampler.sample(x_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "classifiers = [\n",
    "    MLPClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(max_depth=4),\n",
    "    TabNetClassifier(verbose=0),\n",
    "]\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(X_samp, y_samp)\n",
    "    y_pred = clf.predict(X_samp)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_samp, y_pred))\n",
    "\n",
    "    print(\"Azure dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test.values)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2.values)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075075c4-2447-4c64-8efa-471492b1eaef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SYMPROD SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b289d-dbe0-4e87-80bd-4428322b2601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oversampler = sv.SYMPROD()\n",
    "X_samp, y_samp = oversampler.sample(x_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "classifiers = [\n",
    "    MLPClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(max_depth=4),\n",
    "    TabNetClassifier(verbose=0),\n",
    "]\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(X_samp, y_samp)\n",
    "    y_pred = clf.predict(X_samp)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_samp, y_pred))\n",
    "\n",
    "    print(\"Azure dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test.values)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2.values)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
